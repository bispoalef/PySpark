# Projeto de Análise de Dados com PySpark e Google Colab

Este projeto tem como objetivo demonstrar o uso do PySpark e Google Colab para a análise de dados. Utilizando o ambiente do Colab, um ambiente baseado em nuvem para desenvolvimento 
e colaboração de notebooks Jupyter, combinado com a potência do PySpark, é possível manipular grandes conjuntos de dados de forma eficiente e realizar análises complexas.

## Descrição do Projeto

Neste projeto, você encontrará um código em Python que utiliza o PySpark para criar um pipeline de análise de dados. O pipeline começa com a leitura
de múltiplos arquivos de dados, que são combinados em um único DataFrame. Em seguida, diversas transformações e operações são aplicadas nesse DataFrame para realizar análises específicas. 
O projeto é desenvolvido em um notebook Jupyter do Google Colab para facilitar a execução e a visualização dos resultados.

## Como Executar o Projeto

Para executar este projeto, siga as etapas abaixo:

1. Faça o download ou clone o repositório do GitHub em sua máquina local.
2. Acesse o Google Colab e faça o upload do notebook Jupyter (*.ipynb).
3. Abra o notebook no Google Colab e execute cada célula sequencialmente.

## Contato

Em caso de dúvidas ou sugestões relacionadas a este projeto, sinta-se à vontade para entrar em contato comigoatráveis do [Linkedin](https://www.linkedin.com/in/alef-bispo/).

Espero que este projeto seja útil para você e inspire suas próprias análises de dados usando o PySpark e o Google Colab!


## Imagens do projeto
![image](https://github.com/bispoalef/PySpark/assets/111475913/c07b2d61-1397-43fb-b568-8f29fb5f100d)

![image](https://github.com/bispoalef/PySpark/assets/111475913/ed22c9bb-f6fd-4abf-ad0e-911d8eb8c1ee)
