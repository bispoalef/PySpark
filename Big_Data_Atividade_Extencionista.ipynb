{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Wfz1G9W1ZQqV",
        "outputId": "fd1ae260-932d-43f7-89e0-ba70bbf10cfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f669462e860>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://4b9c5a824e52:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ],
      "source": [
        "# Instalar jdk\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Instalar hadoop\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
        "\n",
        "# Extrair arquivo\n",
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz\n",
        "\n",
        "# Importando sistema operacional\n",
        "import os\n",
        "\n",
        "# Criando variavel de ambiente Java\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "# Criando variavel de ambiente Spark\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\"\n",
        "\n",
        "# Pacote Python para fazer integração do Apache Spark\n",
        "!pip install -q findspark\n",
        "\n",
        "# importando o spark\n",
        "import findspark\n",
        "\n",
        "# Iniciando o spark\n",
        "findspark.init()\n",
        "\n",
        "# Classe central no Spark que fornece uma interface para programação em Spark com DataFrames\n",
        "from pyspark.sql import *\n",
        "\n",
        "# Import de funções de tratamento de data frame\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Importando todos os tipos para tratamendo de dados\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "# Criando variavel spark\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# testando variavel\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando os dados baixados da SEFAZ\n",
        "file_paths = [\"/dadosSefaz/Despesa_por_Mes.csv\",\n",
        "              \"/dadosSefaz/Despesa_por_Mes (1).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (2).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (3).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (4).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (5).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (6).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (7).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (8).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (9).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (10).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (11).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (12).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (13).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (14).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (15).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (16).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (17).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (18).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (19).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (20).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (21).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (22).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (23).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (24).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (25).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (26).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (27).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (28).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (29).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (30).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (31).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (32).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (33).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (34).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (35).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (36).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (37).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (38).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (39).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (40).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (41).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (42).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (43).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (44).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (45).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (46).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (47).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (48).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (49).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (50).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (51).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (52).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (53).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (54).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (55).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (56).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (57).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (58).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (59).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (60).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (61).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (62).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (63).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (64).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (65).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (66).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (67).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (68).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (69).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (70).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (71).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (72).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (73).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (74).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (75).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (76).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (77).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (78).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (79).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (80).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (81).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (82).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (83).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (84).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (85).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (86).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (87).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (88).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (89).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (90).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (91).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (92).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (93).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (94).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (95).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (96).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (97).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (98).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (99).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (100).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (101).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (102).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (103).csv\",\n",
        "    \"/dadosSefaz/Despesa_por_Mes (104).csv\"]"
      ],
      "metadata": {
        "id": "JgIfkGjCbMTR"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lendo dados e atribuindo para variavel\n",
        "dataFrame = spark.read.csv(file_paths, inferSchema=True)\n",
        "\n",
        "# Verificando a tipagem \n",
        "type(dataFrame)\n",
        "\n",
        "# Tratando dados do data frame (excluindo coluna vazia, renomeando e tipando os dados)\n",
        "dataFrame = dataFrame.drop(\"_c1\")\n",
        "dataFrame = dataFrame.withColumnRenamed(\"_c0\", \"Orgao\") \\\n",
        "       .withColumnRenamed(\"_c2\", \"Data\") \\\n",
        "       .withColumnRenamed(\"_c3\", \"Nr_da_OB\") \\\n",
        "       .withColumnRenamed(\"_c4\", \"Nr_do_Empenho\") \\\n",
        "       .withColumnRenamed(\"_c5\", \"Codigo_Favorecido\") \\\n",
        "       .withColumnRenamed(\"_c6\", \"Nome_Favorecido\") \\\n",
        "       .withColumnRenamed(\"_c7\", \"Valor_Bruto\") \\\n",
        "       .withColumnRenamed(\"_c8\", \"Valor_Retido\") \\\n",
        "       .withColumnRenamed(\"_c9\", \"Valor_Pago\") \\\n",
        "       .withColumn(\"Data\", to_date(col(\"Data\"), \"dd/MM/yyyy\")) \\\n",
        "       .withColumn(\"Valor_Bruto\", regexp_replace(col(\"Valor_Bruto\"), \"\\\\.\", \"\").cast(\"string\")) \\\n",
        "       .withColumn(\"Valor_Retido\", regexp_replace(col(\"Valor_Retido\"), \"\\\\.\", \"\").cast(\"string\")) \\\n",
        "       .withColumn(\"Valor_Pago\", regexp_replace(col(\"Valor_Pago\"), \"\\\\.\", \"\").cast(\"string\")) \\\n",
        "       .withColumn(\"Valor_Bruto\", regexp_replace(col(\"Valor_Bruto\"), \",\", \".\").cast(\"double\")) \\\n",
        "       .withColumn(\"Valor_Retido\", regexp_replace(col(\"Valor_Retido\"), \",\", \".\").cast(\"double\")) \\\n",
        "       .withColumn(\"Valor_Pago\", regexp_replace(col(\"Valor_Pago\"), \",\", \".\").cast(\"double\"))\n",
        "\n",
        "# Excluindo primeira linha das tabelas\n",
        "dataFrame = dataFrame.subtract(dataFrame.limit(1))\n",
        "\n",
        "# Removendo dados duplicados\n",
        "dataFrame = dataFrame.dropDuplicates([\"Data\", \"Nr_da_OB\", \"Codigo_Favorecido\",\n",
        "                                      \"Nome_Favorecido\", \"Valor_Bruto\"]) \\\n",
        "                                      .orderBy(col(\"Data\"))\n"
      ],
      "metadata": {
        "id": "nnC9pUCfbyYC"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtando outliers\n",
        "dataFrameCopia = dataFrame\n",
        "\n",
        "coluna = 'Valor_Bruto'\n",
        "desvio_padrao = dataFrameCopia.select(stddev(col(coluna))).first()[0]\n",
        "media = dataFrameCopia.select(mean(col(coluna))).first()[0]\n",
        "menor_outlier = media - 3 * desvio_padrao\n",
        "maior_outlier = media + 3 * desvio_padrao\n",
        "outliers = dataFrameCopia.filter((col(coluna) < menor_outlier) | (col(coluna) > maior_outlier))\n",
        "\n",
        "outliers.coalesce(1).write.csv(\"/downloads/outliers\", mode=\"overwrite\")\n",
        "\n",
        "outliers.show()"
      ],
      "metadata": {
        "id": "VVL4j1tshfpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removendo registros de 2023\n",
        "\n",
        "df = outliers.filter(col('Data').cast('string').startswith('2023') == False)\n",
        "df.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfSMuiHPrpm2",
        "outputId": "35ec712c-69ea-4f4e-87cd-bfbf772ecdf2"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+--------+-------------+-----------------+--------------------+-----------+------------+----------+\n",
            "|Orgao|      Data|Nr_da_OB|Nr_do_Empenho|Codigo_Favorecido|     Nome_Favorecido|Valor_Bruto|Valor_Retido|Valor_Pago|\n",
            "+-----+----------+--------+-------------+-----------------+--------------------+-----------+------------+----------+\n",
            "|SEFAZ|2015-01-29|    1454| 2015NE000093|   00360305000104|CAIXA ECONOMICA F...|  7412580.0|         0.0| 7412580.0|\n",
            "|SEFAZ|2015-01-29|    1398| 2015NE000063|   00000000001759| BANCO DO BRASIL S/A| 3666762.87|         0.0|3666762.87|\n",
            "+-----+----------+--------+-------------+-----------------+--------------------+-----------+------------+----------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criando uma tempView para poder usar dataFrame em SQL\n",
        "\n",
        "df.createOrReplaceTempView(\"pagamentos\")"
      ],
      "metadata": {
        "id": "SLLNRdmzhvYD"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Valor total pago\n",
        "\n",
        "Valor_Total_Pago_SQL = spark.sql(\"\"\"\n",
        "SELECT SUM(Valor_Pago) AS Valor_Total_Pago\n",
        "FROM pagamentos\n",
        "WHERE Data >= '2015-01-29'\n",
        "\"\"\"\n",
        ").withColumn('Valor_Total_Pago', format_number(col('Valor_Total_Pago'), 2))\n",
        "\n",
        "Valor_Total_Pago_SQL.coalesce(1).write.csv(\"/downloads/Valor_Total_Pago_SQL\", mode=\"overwrite\")\n",
        "\n",
        "Valor_Total_Pago_SQL.show()"
      ],
      "metadata": {
        "id": "HSrkAxsKhwcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34eb9424-a160-48b0-cfba-0d9e43b910d2"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|Valor_Total_Pago|\n",
            "+----------------+\n",
            "|2,308,054,177.79|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Média de valores pagos\n",
        "\n",
        "Media_Valores_Pagos_SQL = spark.sql(\"\"\"\n",
        "SELECT AVG(Valor_Pago) AS Media_Valor_Pago\n",
        "FROM pagamentos\n",
        "WHERE Data >= '2015-01-29'\n",
        "\"\"\"\n",
        ").withColumn('Media_Valor_Pago', format_number(col('Media_Valor_Pago'), 2))\n",
        "\n",
        "\n",
        "Media_Valores_Pagos_SQL.coalesce(1).write.csv(\"/downloads/Media_Valores_Pagos_SQL\", mode=\"overwrite\")\n",
        "\n",
        "Media_Valores_Pagos_SQL.show()"
      ],
      "metadata": {
        "id": "HfHuQs8ghxrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8155b66c-0dfe-43a0-eb34-8e268809ad12"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|Media_Valor_Pago|\n",
            "+----------------+\n",
            "|    4,579,472.57|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Valores pagos ao favorecido por ano\n",
        "\n",
        "Total_Valores_Pagos_por_Ano_SQL = spark.sql(\"\"\"\n",
        "SELECT YEAR(Data) AS Ano, SUM(Valor_Pago) AS Valor_Pago_Por_Ano\n",
        "FROM pagamentos\n",
        "WHERE Data >= '2015-01-29'\n",
        "GROUP BY Ano\n",
        "ORDER BY Ano\n",
        "\"\"\"\n",
        ").withColumn('Valor_Pago_Por_Ano', format_number(col('Valor_Pago_Por_Ano'), 2))\n",
        "\n",
        "\n",
        "Total_Valores_Pagos_por_Ano_SQL.coalesce(1).write.csv(\"/downloads/Total_Valores_Pagos_por_Ano_SQL\", mode=\"overwrite\")\n",
        "\n",
        "Total_Valores_Pagos_por_Ano_SQL.show()"
      ],
      "metadata": {
        "id": "wqmlMx-Vhymh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f60d2b-4e07-4c6e-ccfd-22630a11c5f2"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------+\n",
            "| Ano|Valor_Pago_Por_Ano|\n",
            "+----+------------------+\n",
            "|2015|    110,089,471.69|\n",
            "|2016|    124,212,390.80|\n",
            "|2017|    289,511,255.94|\n",
            "|2018|    394,297,931.43|\n",
            "|2019|    343,955,432.71|\n",
            "|2020|    321,161,215.66|\n",
            "|2021|    404,320,345.96|\n",
            "|2022|    320,506,133.60|\n",
            "+----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de favorecidos e valores de pagamento\n",
        "\n",
        "Lista_Favorecidos_e_Pagamentos = spark.sql(\"\"\"\n",
        "SELECT Nome_Favorecido, Valor_Pago\n",
        "FROM pagamentos\n",
        "WHERE Data >= '2015-01-29'\n",
        "\"\"\"\n",
        ").withColumn('Valor_Pago', format_number(col('Valor_Pago'), 2))\n",
        "\n",
        "Lista_Favorecidos_e_Pagamentos.coalesce(1).write.csv(\"/downloads/Lista_Favorecidos_e_Pagamentos\", mode=\"overwrite\")\n",
        "\n",
        "Lista_Favorecidos_e_Pagamentos.show()"
      ],
      "metadata": {
        "id": "KRUyVIFbhz1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eda9cd9-f7af-4490-8254-7c6948bf4d4f"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+\n",
            "|     Nome_Favorecido|   Valor_Pago|\n",
            "+--------------------+-------------+\n",
            "|BANCO NACIONAL DE...| 4,255,555.56|\n",
            "| BANCO DO BRASIL S/A| 3,228,908.01|\n",
            "| BANCO DO BRASIL S/A| 4,312,944.02|\n",
            "| BANCO DO BRASIL S/A| 3,666,762.87|\n",
            "|CAIXA ECONOMICA F...| 7,412,580.00|\n",
            "| BANCO DO BRASIL S/A| 3,635,733.92|\n",
            "| BANCO DO BRASIL S/A| 4,349,613.35|\n",
            "|BANCO NACIONAL DE...| 4,255,555.56|\n",
            "| BANCO DO BRASIL S/A| 4,328,917.64|\n",
            "| BANCO DO BRASIL S/A| 3,296,089.52|\n",
            "| BANCO DO BRASIL S/A| 3,712,148.00|\n",
            "|BANCO NACIONAL DE...| 4,258,189.84|\n",
            "| BANCO DO BRASIL S/A| 4,425,999.60|\n",
            "| BANCO DO BRASIL S/A| 3,969,163.30|\n",
            "|BANCO NACIONAL DE...| 4,259,815.25|\n",
            "|CAIXA ECONOMICA F...| 2,606,054.35|\n",
            "|CAIXA ECONOMICA F...|-2,606,054.35|\n",
            "| BANCO DO BRASIL S/A| 4,014,726.59|\n",
            "| BANCO DO BRASIL S/A| 4,415,457.38|\n",
            "| BANCO DO BRASIL S/A| 4,030,000.00|\n",
            "+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados_2022 = outliers.filter(outliers['Data'].contains('2022'))"
      ],
      "metadata": {
        "id": "xASsxzGwzhfD"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando previsão utilizando modelo ARIMA\n",
        "\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# Converter DataFrame do Spark para DataFrame do pandas\n",
        "pandas_df = dados_2022.toPandas()\n",
        "\n",
        "# Converter a coluna \"Data\" para o formato datetime\n",
        "pandas_df['Data'] = pd.to_datetime(pandas_df['Data'])\n",
        "\n",
        "# Redefinir o índice como uma sequência numérica simples\n",
        "pandas_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Criar o modelo ARIMA\n",
        "order = (1, 0, 1) \n",
        "model = ARIMA(pandas_df['Valor_Pago'], order=order)\n",
        "\n",
        "# Ajustar o modelo aos dados\n",
        "model_fit = model.fit()\n",
        "\n",
        "\n",
        "  # Fazendo previsões para os próximos 3 períodos\n",
        "forecast = model_fit.predict(start=1, end=5)\n",
        "\n",
        "print(forecast)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf5jtu2EGUtC",
        "outputId": "b1817462-98b9-44d4-bf3c-5ca2a406f0c2"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    3.800044e+06\n",
            "2    3.692578e+06\n",
            "3    5.247890e+06\n",
            "4    5.530060e+06\n",
            "5    4.895500e+06\n",
            "Name: predicted_mean, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_results = [ 3.80044e+06, 3.69257e+06, 5.247890e+06, 5.5060e+06, 4.895500e+06]\n",
        "\n",
        "# Criar lista de tuplas com os valores e meses correspondentes\n",
        "forecast_data = [\n",
        "    ('2023-01', forecast_results[0]),\n",
        "    ('2023-02', forecast_results[1]),\n",
        "    ('2023-03', forecast_results[2]),\n",
        "    ('2023-04', forecast_results[3]),\n",
        "    ('2023-05', forecast_results[4])\n",
        "]\n",
        "\n",
        "# Criar o esquema do DataFrame\n",
        "schema = StructType([\n",
        "    StructField('Data', StringType(), nullable=False),\n",
        "    StructField('Valor_Pago', FloatType(), nullable=False)\n",
        "])\n",
        "\n",
        "# Criar DataFrame do Spark com os valores previstos\n",
        "arima_2023 = spark.createDataFrame(forecast_data, schema)\n",
        "\n",
        "# Exibir DataFrame do Spark\n",
        "arima_2023.withColumn('Valor_Pago', format_number(col('Valor_Pago'), 2))\n",
        "\n",
        "\n",
        "arima_2023.coalesce(1).write.csv(\"/downloads/arima_2023\", mode=\"overwrite\")\n",
        "\n",
        "arima_2023.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWvljPdZ0J1F",
        "outputId": "4f75942e-e447-4179-c7ae-7b46accc5a57"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|   Data|Valor_Pago|\n",
            "+-------+----------+\n",
            "|2023-01| 3800440.0|\n",
            "|2023-02| 3692570.0|\n",
            "|2023-03| 5247890.0|\n",
            "|2023-04| 5506000.0|\n",
            "|2023-05| 4895500.0|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}