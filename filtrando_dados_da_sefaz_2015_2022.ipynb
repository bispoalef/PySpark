{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Instalar jdk"
      ],
      "metadata": {
        "id": "vB2K2rrzO_GK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RXG6ZthCO0UI"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "instalar hadoop"
      ],
      "metadata": {
        "id": "zHmf0btPPH4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "lJI600v3PLUW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "extrair arquivo"
      ],
      "metadata": {
        "id": "13KECaACP8nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "5irpNZyuP_Nm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "permite interagir com o sistema operacional"
      ],
      "metadata": {
        "id": "R2-zy_STQRqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "_OvDxFM_QST6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "criando variavel de ambiente java"
      ],
      "metadata": {
        "id": "9WHWbuQqQW9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "BRlQ8XtJQZtO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "criando variavel de ambiente spark"
      ],
      "metadata": {
        "id": "ed1muJuGQbOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "y-XvHNnCQaoL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pacote Python que facilita a integração do Apache Spark"
      ],
      "metadata": {
        "id": "M8PsqK3HQtkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "wH2QfzzsQusE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "importando no projeto"
      ],
      "metadata": {
        "id": "dNDSh5_WQypy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark"
      ],
      "metadata": {
        "id": "XQV47aaDQ4vH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "iniciando findSpark"
      ],
      "metadata": {
        "id": "TWpqv38GRNlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "findspark.init()"
      ],
      "metadata": {
        "id": "pTVKKD5QQ882"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "classe central no Spark que fornece uma interface para programação em Spark com DataFrames e Datasets."
      ],
      "metadata": {
        "id": "cj7HbDyuRJB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "SFfbFeUzRJku"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "V61RzL6l1LCN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "yrXkm7EqYmlK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "criando variavel do sparkSession"
      ],
      "metadata": {
        "id": "HJbj8tRzRUUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkSession.builder.master('local[*]').getOrCreate()"
      ],
      "metadata": {
        "id": "qsiQ-3eBRZcC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "OcD2D4DpbEM5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testando a variavél para ver se esta tudo certo"
      ],
      "metadata": {
        "id": "lBpkoa01Rfi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "edewfyMTRd4T",
        "outputId": "d4c26358-51e5-4fdf-e0ae-9c7ad222df73"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f198d4a96f0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3a224844ff0a:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "setando os arquivos vindos da SEFAZ"
      ],
      "metadata": {
        "id": "eFufRN1_T6IF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_paths = [\"/sefaz/Receita_SE_2015.csv\", \n",
        "              \"/sefaz/Receita_SE_2016.csv\", \n",
        "              \"/sefaz/Receita_SE_2017.csv\", \n",
        "              \"/sefaz/Receita_SE_2018.csv\", \n",
        "              \"/sefaz/Receita_SE_2019.csv\", \n",
        "              \"/sefaz/Receita_SE_2020.csv\", \n",
        "              \"/sefaz/Receita_SE_2021.csv\", \n",
        "              \"/sefaz/Receita_SE_2022.csv\"]"
      ],
      "metadata": {
        "id": "gVK3VhDCT-_7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "convertendo dados para dataFrame"
      ],
      "metadata": {
        "id": "KFyql0L2Wd70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrame = spark.read.csv(file_paths)"
      ],
      "metadata": {
        "id": "wQqS2la0bI9l"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vefificando se realmente foi convertido a data frame"
      ],
      "metadata": {
        "id": "295l_vSxU7pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataFrame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpcuC4P6U6oc",
        "outputId": "6d0d87a4-00ca-4be1-b5f1-33b899014576"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "verificando o se foi convertido corretamente os tipos dad variaveis"
      ],
      "metadata": {
        "id": "K-sbgCo5ezf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrame.printSchema()"
      ],
      "metadata": {
        "id": "HyTIHiPdVDaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "renomeando colunas"
      ],
      "metadata": {
        "id": "zBRKlIcz7TOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrame = dataFrame.withColumnRenamed(\"_c1\", \"SGL_ORGAO\") \\\n",
        "       .withColumnRenamed(\"_c2\", \"MES\") \\\n",
        "       .withColumnRenamed(\"_c3\", \"ANO\") \\\n",
        "       .withColumnRenamed(\"_c4\", \"COD_UNIDADE_GOV\") \\\n",
        "       .withColumnRenamed(\"_c5\", \"SGL_UNIDADE_GOV\") \\\n",
        "       .withColumnRenamed(\"_c6\", \"COD_FONTE_RECURSO\") \\\n",
        "       .withColumnRenamed(\"_c7\", \"NOM_FONTE_RECURSO\") \\\n",
        "       .withColumnRenamed(\"_c8\", \"COD_NATUREZA\") \\\n",
        "       .withColumnRenamed(\"_c9\", \"VL_ARRECADADA\")"
      ],
      "metadata": {
        "id": "JCxZJBQQy6Yy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "excluindo primeira linha das tabelas"
      ],
      "metadata": {
        "id": "sgeT8z7p7V04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrame = dataFrame.subtract(dataFrame.limit(1))"
      ],
      "metadata": {
        "id": "N0-YloRtz-xb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testando se tudo ocorreu como esperado"
      ],
      "metadata": {
        "id": "Yf-wPki67akw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrame.show()"
      ],
      "metadata": {
        "id": "DGv6l8nSWSlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "filtrando dados apenas pelo codigo da SEFAZ"
      ],
      "metadata": {
        "id": "zMre5_FC7gGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtrado = dataFrame.filter(col(\"COD_ORGAO\") == \"16000\")"
      ],
      "metadata": {
        "id": "XsAEqy-3fc4_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "conferindo novamente"
      ],
      "metadata": {
        "id": "4cLa7TUw7nPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtrado.show()"
      ],
      "metadata": {
        "id": "qkV4pF29fsL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "excluindo campos vazios ou null"
      ],
      "metadata": {
        "id": "FPxcJ96n7qAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtrado = df_filtrado.na.drop()"
      ],
      "metadata": {
        "id": "MtAWRTYo2jix"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "criando o arquivo para exportar"
      ],
      "metadata": {
        "id": "9VEaQIqQ7w9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtrado.coalesce(1).write.csv(\"/sefaz/todos_dados_sefaz-2015-2022\", mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "ms-9oeFsgS4e"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}